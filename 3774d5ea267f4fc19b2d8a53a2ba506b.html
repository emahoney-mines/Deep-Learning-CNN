<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>eb2c45b314924e03820814e2fe459c2b</title>
  <style>
    html {
      line-height: 1.5;
      font-family: Georgia, serif;
      font-size: 20px;
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 1em;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, 'Lucida Console', Consolas, monospace;
      font-size: 85%;
      margin: 0;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      background-color: #1a1a1a;
      border: none;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      {   }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span.al { color: #ff0000; font-weight: bold; } /* Alert */
    code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
    code span.at { color: #7d9029; } /* Attribute */
    code span.bn { color: #40a070; } /* BaseN */
    code span.bu { color: #008000; } /* BuiltIn */
    code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #4070a0; } /* Char */
    code span.cn { color: #880000; } /* Constant */
    code span.co { color: #60a0b0; font-style: italic; } /* Comment */
    code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
    code span.do { color: #ba2121; font-style: italic; } /* Documentation */
    code span.dt { color: #902000; } /* DataType */
    code span.dv { color: #40a070; } /* DecVal */
    code span.er { color: #ff0000; font-weight: bold; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #40a070; } /* Float */
    code span.fu { color: #06287e; } /* Function */
    code span.im { color: #008000; font-weight: bold; } /* Import */
    code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
    code span.kw { color: #007020; font-weight: bold; } /* Keyword */
    code span.op { color: #666666; } /* Operator */
    code span.ot { color: #007020; } /* Other */
    code span.pp { color: #bc7a00; } /* Preprocessor */
    code span.sc { color: #4070a0; } /* SpecialChar */
    code span.ss { color: #bb6688; } /* SpecialString */
    code span.st { color: #4070a0; } /* String */
    code span.va { color: #19177c; } /* Variable */
    code span.vs { color: #4070a0; } /* VerbatimString */
    code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
    .display.math{display: block; text-align: center; margin: 0.5rem auto;}
  </style>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<section id="csci-470-activities-and-case-studies" class="cell markdown"
id="uwtEu7DwciEk">
<h2>CSCI 470 Activities and Case Studies</h2>
<ol>
<li>For all activities, you are allowed to collaborate with a
partner.</li>
<li>For case studies, you should work individually and are
<strong>not</strong> allowed to collaborate.</li>
</ol>
<p>By filling out this notebook and submitting it, you acknowledge that
you are aware of the above policies and are agreeing to comply with
them.</p>
</section>
<div class="cell markdown" id="VEmA5WcgciFA">
<p>Some considerations with regard to how these notebooks will be
graded:</p>
<ol>
<li>Cells in which "# YOUR CODE HERE" is found are the cells where your
graded code should be written.</li>
<li>In order to test out or debug your code you may also create notebook
cells or edit existing notebook cells other than "# YOUR CODE HERE". We
actually highly recommend you do so to gain a better understanding of
what is happening. However, during grading, <strong>these changes are
ignored</strong>.</li>
<li>You must ensure that all your code for the particular task is
available in the cells that say "# YOUR CODE HERE"</li>
<li>Every cell that says "# YOUR CODE HERE" is followed by a "raise
NotImplementedError". You need to remove that line. During grading, if
an error occurs then you will not receive points for your work in that
section.</li>
<li>If your code passes the "assert" statements, then no output will
result. If your code fails the "assert" statements, you will get an
"AssertionError". Getting an assertion error means you will not receive
points for that particular task.</li>
<li>If you edit the "assert" statements to make your code pass, they
will still fail when they are graded since the "assert" statements will
revert to the original. Make sure you don't edit the assert
statements.</li>
<li>We may sometimes have "hidden" tests for grading. This means that
passing the visible "assert" statements is not sufficient. The "assert"
statements are there as a guide but you need to make sure you understand
what you're required to do and ensure that you are doing it correctly.
Passing the visible tests is necessary but not sufficient to get the
grade for that cell.</li>
<li>When you are asked to define a function, make sure you
<strong>don't</strong> use any variables outside of the parameters
passed to the function. You can think of the parameters being passed to
the function as a hint. Make sure you're using all of those
variables.</li>
<li>Finally, <strong>make sure you run "Kernel &gt; Restart and Run
All"</strong> and pass all the asserts before submitting. If you don't
restart the kernel, there may be some code that you ran and deleted that
is still being used and that was why your asserts were passing.</li>
</ol>
</div>
<section id="deep-learning---convolutional-neural-networks"
class="cell markdown" data-deletable="false" data-editable="false"
id="djcCdVF-ciFB"
data-nbgrader="{&quot;cell_type&quot;:&quot;markdown&quot;,&quot;checksum&quot;:&quot;47ccadb4be48caa31405858fec2162fb&quot;,&quot;grade&quot;:false,&quot;grade_id&quot;:&quot;cell-8624ebbfca3f9d05&quot;,&quot;locked&quot;:true,&quot;schema_version&quot;:3,&quot;solution&quot;:false}">
<h1>Deep Learning - Convolutional Neural Networks</h1>
<p>In this exercise we'll compare a simple fully-connected (dense)
feedforward neural network with a convolutional neural network at
predicting the <a href="http://yann.lecun.com/exdb/mnist/">MNIST
handwritten digits, drawn in a 28x28 pixel image</a>.</p>
<p>Note that each sample we're using is a grayscale image - that means
that each sample (image) is a matrix of values whereas previously our
samples had been vectors. You will need to modify the data to work with
this accordingly. For example, keras' <a
href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense">Dense</a>
layers expect their inputs to be vectors so whenever you're using a <a
href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense">Dense</a>
layer, make sure you convert its inputs to a vector, if needed. In
keras, you can convert a matrix (or tensor) to a vector using the <a
href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/Flatten">Flatten</a>
layer. For more complex changes where you want to cusomize the exact
shape of the values, you can use the <a
href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/Reshape">Reshape</a>
layer.</p>
</section>
<div class="cell code" id="BszeXmSMciFB"
data-nbgrader="{&quot;grade&quot;:false,&quot;grade_id&quot;:&quot;cell-69b5ab127f73f4ab&quot;,&quot;locked&quot;:false,&quot;schema_version&quot;:3,&quot;solution&quot;:false}">
<div class="sourceCode" id="cb1"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> tensorflow <span class="im">as</span> tf</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tensorflow.keras.datasets <span class="im">import</span> cifar10, mnist</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tensorflow.keras <span class="im">import</span> Sequential</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tensorflow.keras.layers <span class="im">import</span> Input, Dense, Dropout, Flatten, Conv2D, MaxPool2D</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> scipy</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">0</span>)</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>tf.random.set_seed(<span class="dv">0</span>)</span></code></pre></div>
</div>
<div class="cell code"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="NqMEWHMsciFC"
data-nbgrader="{&quot;grade&quot;:false,&quot;grade_id&quot;:&quot;cell-2f12505f86743d95&quot;,&quot;locked&quot;:false,&quot;schema_version&quot;:3,&quot;solution&quot;:false}"
data-outputId="c2305266-97c0-4306-9598-24d9b74163b5">
<div class="sourceCode" id="cb2"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>(x_train, y_train), (x_test, y_test) <span class="op">=</span> mnist.load_data()</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz
11490434/11490434 [==============================] - 0s 0us/step
</code></pre>
</div>
</div>
<div class="cell code"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="nMMkb9lpciFC"
data-nbgrader="{&quot;grade&quot;:false,&quot;grade_id&quot;:&quot;cell-43ee2cdae7268658&quot;,&quot;locked&quot;:false,&quot;schema_version&quot;:3,&quot;solution&quot;:false}"
data-outputId="25619e75-2830-44df-b6af-0d03eb198a6f">
<div class="sourceCode" id="cb4"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>s1 <span class="op">=</span> x_train.shape</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>s2 <span class="op">=</span> x_test.shape</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;The MNIST data was loaded with </span><span class="sc">{</span>s1[<span class="dv">0</span>]<span class="sc">}</span><span class="ss"> training samples and </span><span class="sc">{</span>s2[<span class="dv">0</span>]<span class="sc">}</span><span class="ss"> testing samples.&quot;</span>)</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Each sample is a </span><span class="sc">{</span>s1[<span class="dv">1</span>]<span class="sc">}</span><span class="ss"> x </span><span class="sc">{</span>s1[<span class="dv">2</span>]<span class="sc">}</span><span class="ss"> pixel image.&quot;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>The MNIST data was loaded with 60000 training samples and 10000 testing samples.
Each sample is a 28 x 28 pixel image.
</code></pre>
</div>
</div>
<div class="cell code"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="MYatlvzQciFD"
data-nbgrader="{&quot;grade&quot;:false,&quot;grade_id&quot;:&quot;cell-5c9c291b795e1704&quot;,&quot;locked&quot;:false,&quot;schema_version&quot;:3,&quot;solution&quot;:false}"
data-outputId="09166f85-11cf-47c0-8ee9-6c38a9641ccb">
<div class="sourceCode" id="cb6"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Here&#39;s an example hand drawn digit&#39;s image</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>example <span class="op">=</span> x_train[<span class="dv">0</span>]</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>example</span></code></pre></div>
<div class="output execute_result" data-execution_count="6">
<pre><code>array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
          0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
          0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
          0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
          0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
          0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,
         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,
          0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,
        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,
          0,   0],
       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,
        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,
          0,   0],
       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,
        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,
          0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,
        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,
          0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,
         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
          0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,
        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
          0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,
        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
          0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,
        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,
          0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,
          0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,
          0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,
          0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,
          0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,
          0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,
        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,
          0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,
        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,
          0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,
        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,
          0,   0],
       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,
        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
          0,   0],
       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,
         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
          0,   0],
       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,
          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
          0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
          0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
          0,   0],
       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
          0,   0]], dtype=uint8)</code></pre>
</div>
</div>
<div class="cell code"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:430}"
id="Q0CEAzfaciFD" data-outputId="22006c37-a56a-4614-88c2-ef101a245846">
<div class="sourceCode" id="cb8"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Now let&#39;s plot that matrix to better understand what&#39;s happening here...</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>_ <span class="op">=</span> plt.imshow(example, cmap<span class="op">=</span><span class="st">&quot;gray&quot;</span>)</span></code></pre></div>
<div class="output display_data">
<p><img
src="vertopal_3774d5ea267f4fc19b2d8a53a2ba506b/76abcc11ea8d9dde1ee7d584eb335c49df4e52c7.png" /></p>
</div>
</div>
<div class="cell code"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="otB80CT6ciFD" data-outputId="36505d2e-1b5a-4092-fc42-37684b730fdd">
<div class="sourceCode" id="cb9"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co"># In this cell, we&#39;ll print out the unique labels in the data.</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a><span class="co"># We&#39;re predicting the digit in an image and we have images of</span></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a><span class="co"># all 10 (&#39;0&#39; to &#39;9&#39;) digits.</span></span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(np.unique(y_test))</span></code></pre></div>
<div class="output stream stdout">
<pre><code>[0 1 2 3 4 5 6 7 8 9]
</code></pre>
</div>
</div>
<section id="convolutions" class="cell markdown" id="ALZ9gEk2ciFE">
<h3>Convolutions</h3>
<p>Most engineers in computer scientists are familiar with convolutions.
If you're not, or you need a refresher, try <a
href="https://electricalacademia.com/signals-and-systems/example-of-discrete-time-graphical-convolution/">this
article on discrete convolutions</a>. The article is on discrete
<em>time</em> convolutions, but the process is the same for discrete
<em>spatial</em> convolutions--which is what we are doing when we
perform a 2D convolution on an image.</p>
<p>To check your basic understanding of convolutions, implement the
function below, which computes what the output image shape will be for a
given convolutional kernel (filter) applied to a given input image.
Recall that for a given dimension, the length of the output of a
convolution is:</p>
<p><code>L_out = L_in - L_kernel + 1</code></p>
<p>where L_in is the length of the input (pixels), L_kernel is the
length of the filter/kernel, and L_out is the length of the output
(pixels)</p>
<p>The equation above assumes that we haven't added any "padding" to the
input image, e.g., pixels of value 0 that we use to extend/enlarge the
input image. In Keras, you'll see that a user can specify padding as a
scalar number of pixels to add <strong>to each side of the
image</strong>. Thus,</p>
<p><code>L_in_padded = L_in + 2*padding</code><br />
<code>L_out = L_in_padded - L_kernel + 1</code><br />
<code>L_out = L_in + 2*padding - L_kernel + 1</code></p>
<p>Finally, we may want to use a convolution in which the kernel doesn't
"slide" along the input in single-pixel steps, but in multiple-pixel
steps, of step size <code>stride</code>. You may want to diagram it out
for yourself on a piece of paper (in a manner like that of the article
linked above), but we effectively just need to divide the output length
by the stride value (before adding the 1) to get strided output size.
Because it may be fractional, the final answer is actually the floor of
that previous result. This gives us...</p>
<p><code>L_out = floor( (L_in + 2*padding - L_kernel) / stride + 1 )</code></p>
<p>In the function below, you'll need to implement that equation
separately for the horizontal and vertical dimensions of the image and
kernel. Do not assume that either the image or the kernel are square. In
Python, <code>int()</code> converts a number to an integer, executing a
floor operation if the number is floating-point.</p>
</section>
<div class="cell code" data-deletable="false" id="XgADiINJciFE"
data-nbgrader="{&quot;cell_type&quot;:&quot;code&quot;,&quot;checksum&quot;:&quot;181818b1f77d0f52ace8cfea1f63a385&quot;,&quot;grade&quot;:false,&quot;grade_id&quot;:&quot;cell-887e94c3f19aac00&quot;,&quot;locked&quot;:false,&quot;schema_version&quot;:3,&quot;solution&quot;:true}">
<div class="sourceCode" id="cb11"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> calculate_conv_shape(X, K, padding<span class="op">=</span><span class="dv">0</span>, stride<span class="op">=</span><span class="dv">1</span>):</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">&quot;&quot;&quot;Calculate the shape of the output of a convolution</span></span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a><span class="co">    Args:</span></span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a><span class="co">        X (np.array): The input matrix</span></span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a><span class="co">        K (np.array): The filter matrix</span></span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a><span class="co">        padding (int, optional): Defaults to 0. The padding dimension</span></span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a><span class="co">        stride (int, optional): Defaults to 1. The stride of the convolution</span></span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a><span class="co">        tuple: The shape of the convolution output, height then width</span></span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a><span class="co">    &quot;&quot;&quot;</span></span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a>    <span class="co"># YOUR CODE HERE</span></span>
<span id="cb11-14"><a href="#cb11-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-15"><a href="#cb11-15" aria-hidden="true" tabindex="-1"></a>    H_out <span class="op">=</span> (X.shape[<span class="dv">0</span>] <span class="op">-</span> K.shape[<span class="dv">0</span>] <span class="op">+</span> <span class="dv">2</span> <span class="op">*</span> padding) <span class="op">//</span> stride <span class="op">+</span> <span class="dv">1</span></span>
<span id="cb11-16"><a href="#cb11-16" aria-hidden="true" tabindex="-1"></a>    W_out <span class="op">=</span> (X.shape[<span class="dv">1</span>] <span class="op">-</span> K.shape[<span class="dv">1</span>] <span class="op">+</span> <span class="dv">2</span> <span class="op">*</span> padding) <span class="op">//</span> stride <span class="op">+</span> <span class="dv">1</span></span>
<span id="cb11-17"><a href="#cb11-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-18"><a href="#cb11-18" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb11-19"><a href="#cb11-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-20"><a href="#cb11-20" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> calculate_conv_shape(X, K, padding<span class="op">=</span><span class="dv">0</span>, stride<span class="op">=</span><span class="dv">1</span>):</span>
<span id="cb11-21"><a href="#cb11-21" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Calculate the height and width of the output</span></span>
<span id="cb11-22"><a href="#cb11-22" aria-hidden="true" tabindex="-1"></a>    H_out <span class="op">=</span> (X.shape[<span class="dv">0</span>] <span class="op">-</span> K.shape[<span class="dv">0</span>] <span class="op">+</span> <span class="dv">2</span> <span class="op">*</span> padding) <span class="op">//</span> stride <span class="op">+</span> <span class="dv">1</span></span>
<span id="cb11-23"><a href="#cb11-23" aria-hidden="true" tabindex="-1"></a>    W_out <span class="op">=</span> (X.shape[<span class="dv">1</span>] <span class="op">-</span> K.shape[<span class="dv">1</span>] <span class="op">+</span> <span class="dv">2</span> <span class="op">*</span> padding) <span class="op">//</span> stride <span class="op">+</span> <span class="dv">1</span></span>
<span id="cb11-24"><a href="#cb11-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-25"><a href="#cb11-25" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> (H_out, W_out)</span>
<span id="cb11-26"><a href="#cb11-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-27"><a href="#cb11-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-28"><a href="#cb11-28" aria-hidden="true" tabindex="-1"></a>    <span class="co"># raise NotImplementedError()</span></span></code></pre></div>
</div>
<div class="cell code"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="8W24V1HZciFF"
data-nbgrader="{&quot;grade&quot;:false,&quot;grade_id&quot;:&quot;cell-f77d68a4c1196592&quot;,&quot;locked&quot;:false,&quot;schema_version&quot;:3,&quot;solution&quot;:false}"
data-outputId="2ca3a92d-9d04-4613-8990-f1e69d24d826">
<div class="sourceCode" id="cb12"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Here, we define a &quot;blurring&quot; filter/kernel, that can be applied</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a><span class="co"># to an image to get a blurred output image.</span></span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>blur <span class="op">=</span> np.array([</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>    [<span class="dv">0</span>,    <span class="fl">0.25</span>, <span class="dv">0</span>   ],</span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>    [<span class="fl">0.25</span>, <span class="fl">0.5</span>,  <span class="fl">0.25</span>],</span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>    [<span class="dv">0</span>,    <span class="fl">0.25</span>, <span class="dv">0</span>   ]</span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a><span class="co"># If we pad our 28x28 example image and then convolve it</span></span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a><span class="co"># with the blurring kernel (with stride=1), the output</span></span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a><span class="co"># image should also be 28x28.</span></span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a>calculate_conv_shape(example, blur, padding<span class="op">=</span><span class="dv">1</span>)</span></code></pre></div>
<div class="output execute_result" data-execution_count="10">
<pre><code>(28, 28)</code></pre>
</div>
</div>
<div class="cell code" data-deletable="false" data-editable="false"
id="PiQTdZ0CciFF"
data-nbgrader="{&quot;cell_type&quot;:&quot;code&quot;,&quot;checksum&quot;:&quot;4a69c868df7984fbcf05d18782858c39&quot;,&quot;grade&quot;:true,&quot;grade_id&quot;:&quot;cell-8c49e7193a849321&quot;,&quot;locked&quot;:true,&quot;points&quot;:5,&quot;schema_version&quot;:3,&quot;solution&quot;:false}">
<div class="sourceCode" id="cb14"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>ans <span class="op">=</span> calculate_conv_shape(example, blur, padding<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a><span class="cf">assert</span> <span class="bu">isinstance</span>(ans, <span class="bu">tuple</span>)</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a><span class="cf">assert</span> <span class="bu">isinstance</span>(ans[<span class="dv">0</span>], <span class="bu">int</span>)</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a><span class="cf">assert</span> <span class="bu">isinstance</span>(ans[<span class="dv">1</span>], <span class="bu">int</span>)</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a><span class="cf">assert</span> ans <span class="op">==</span> (<span class="dv">28</span>, <span class="dv">28</span>)</span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>ans <span class="op">=</span> calculate_conv_shape(example, blur, padding<span class="op">=</span><span class="dv">0</span>, stride<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a><span class="cf">assert</span> ans <span class="op">==</span> (<span class="dv">13</span>, <span class="dv">13</span>)</span></code></pre></div>
</div>
<section id="try-out-a-convolution" class="cell markdown"
data-deletable="false" data-editable="false" id="HAXTsFraciFF"
data-nbgrader="{&quot;cell_type&quot;:&quot;markdown&quot;,&quot;checksum&quot;:&quot;926290a0f7c73ec67c02a53e2deb0fe3&quot;,&quot;grade&quot;:false,&quot;grade_id&quot;:&quot;cell-25dbc77554a4c538&quot;,&quot;locked&quot;:true,&quot;schema_version&quot;:3,&quot;solution&quot;:false}">
<h3>Try out a convolution</h3>
<p>To apply a convolution, you can use the <a
href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.ndimage.convolve.html">scipy.ndimage.convolve</a>.
<code>scipy</code> has already been imported for you above.</p>
<p>Convert <code>example</code> to floating point numbers using
<code>example.astype(np.float)</code> before you execute the
convolution.</p>
</section>
<div class="cell code"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:472}"
data-deletable="false" id="sfWJgwm6ciFG"
data-nbgrader="{&quot;cell_type&quot;:&quot;code&quot;,&quot;checksum&quot;:&quot;d28950dc98905e27a1ad46219750ebec&quot;,&quot;grade&quot;:false,&quot;grade_id&quot;:&quot;cell-eaf956c226dd39b7&quot;,&quot;locked&quot;:false,&quot;schema_version&quot;:3,&quot;solution&quot;:true}"
data-outputId="b63abd1f-d676-4190-f698-995a1431b2b2">
<div class="sourceCode" id="cb15"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply the blurring filter to the example and save the output to &quot;blurred_image&quot;.</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Be sure to convert the example from unsigned int numbers to floating-point numbers</span></span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a><span class="co"># beforehand.</span></span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a><span class="co"># YOUR CODE HERE</span></span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy <span class="im">import</span> ndimage</span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert example to float</span></span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a>example_float <span class="op">=</span> example.astype(np.<span class="bu">float</span>)</span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-13"><a href="#cb15-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply the convolution to the example image using the blurring kernel</span></span>
<span id="cb15-14"><a href="#cb15-14" aria-hidden="true" tabindex="-1"></a>blurred_image <span class="op">=</span> ndimage.convolve(example_float, blur, mode<span class="op">=</span><span class="st">&#39;constant&#39;</span>, cval<span class="op">=</span><span class="fl">0.0</span>)</span>
<span id="cb15-15"><a href="#cb15-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-16"><a href="#cb15-16" aria-hidden="true" tabindex="-1"></a><span class="co"># raise NotImplementedError()</span></span>
<span id="cb15-17"><a href="#cb15-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-18"><a href="#cb15-18" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">5</span>))</span>
<span id="cb15-19"><a href="#cb15-19" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">1</span>)</span>
<span id="cb15-20"><a href="#cb15-20" aria-hidden="true" tabindex="-1"></a>plt.imshow(example, cmap<span class="op">=</span><span class="st">&quot;gray&quot;</span>)</span>
<span id="cb15-21"><a href="#cb15-21" aria-hidden="true" tabindex="-1"></a>plt.colorbar()</span>
<span id="cb15-22"><a href="#cb15-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-23"><a href="#cb15-23" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">2</span>)</span>
<span id="cb15-24"><a href="#cb15-24" aria-hidden="true" tabindex="-1"></a>plt.imshow(blurred_image, cmap<span class="op">=</span><span class="st">&quot;gray&quot;</span>)</span>
<span id="cb15-25"><a href="#cb15-25" aria-hidden="true" tabindex="-1"></a>_ <span class="op">=</span> plt.colorbar()</span></code></pre></div>
<div class="output stream stderr">
<pre><code>&lt;ipython-input-14-70738253539f&gt;:11: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  example_float = example.astype(np.float)
</code></pre>
</div>
<div class="output display_data">
<p><img
src="vertopal_3774d5ea267f4fc19b2d8a53a2ba506b/61b52c7989047f5843511170358909df5440a1f4.png" /></p>
</div>
</div>
<div class="cell code"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:472}"
data-deletable="false" id="ohqf8_NlciFG"
data-nbgrader="{&quot;cell_type&quot;:&quot;code&quot;,&quot;checksum&quot;:&quot;cbe761b38b1262f56ec7e75a94c7a54a&quot;,&quot;grade&quot;:false,&quot;grade_id&quot;:&quot;cell-1051e90fd643f6ab&quot;,&quot;locked&quot;:false,&quot;schema_version&quot;:3,&quot;solution&quot;:true}"
data-outputId="c75e4f6e-328b-4453-de56-9f12b94c1f14">
<div class="sourceCode" id="cb17"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a 3x3 filter of your choice (a matrix of numbers) and save it as &quot;my_filter&quot;.</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Then apply that filter to the example and save the output image as &quot;filtered_image&quot;.</span></span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Again, be sure to convert the example from unsigned int numbers to floating-point</span></span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a><span class="co"># numbers beforehand.</span></span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a><span class="co"># YOUR CODE HERE</span></span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a 3x3 filter</span></span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a>my_filter <span class="op">=</span> np.array([</span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a>    [<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">0</span>],</span>
<span id="cb17-13"><a href="#cb17-13" aria-hidden="true" tabindex="-1"></a>    [<span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">1</span>],</span>
<span id="cb17-14"><a href="#cb17-14" aria-hidden="true" tabindex="-1"></a>    [<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">0</span>]</span>
<span id="cb17-15"><a href="#cb17-15" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb17-16"><a href="#cb17-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-17"><a href="#cb17-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert example to floating point numbers</span></span>
<span id="cb17-18"><a href="#cb17-18" aria-hidden="true" tabindex="-1"></a>example_float <span class="op">=</span> example.astype(np.<span class="bu">float</span>)</span>
<span id="cb17-19"><a href="#cb17-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-20"><a href="#cb17-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply the filter to the example</span></span>
<span id="cb17-21"><a href="#cb17-21" aria-hidden="true" tabindex="-1"></a>filtered_image <span class="op">=</span> scipy.ndimage.convolve(example_float, my_filter)</span>
<span id="cb17-22"><a href="#cb17-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-23"><a href="#cb17-23" aria-hidden="true" tabindex="-1"></a><span class="co"># Round the values to the nearest integer and convert back to unsigned int</span></span>
<span id="cb17-24"><a href="#cb17-24" aria-hidden="true" tabindex="-1"></a>filtered_image <span class="op">=</span> np.<span class="bu">round</span>(filtered_image).astype(np.uint8)</span>
<span id="cb17-25"><a href="#cb17-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-26"><a href="#cb17-26" aria-hidden="true" tabindex="-1"></a><span class="co"># raise NotImplementedError()</span></span>
<span id="cb17-27"><a href="#cb17-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-28"><a href="#cb17-28" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">5</span>))</span>
<span id="cb17-29"><a href="#cb17-29" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">1</span>)</span>
<span id="cb17-30"><a href="#cb17-30" aria-hidden="true" tabindex="-1"></a>plt.imshow(example, cmap<span class="op">=</span><span class="st">&quot;gray&quot;</span>)</span>
<span id="cb17-31"><a href="#cb17-31" aria-hidden="true" tabindex="-1"></a>plt.colorbar()</span>
<span id="cb17-32"><a href="#cb17-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-33"><a href="#cb17-33" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">2</span>)</span>
<span id="cb17-34"><a href="#cb17-34" aria-hidden="true" tabindex="-1"></a>plt.imshow(filtered_image, cmap<span class="op">=</span><span class="st">&quot;gray&quot;</span>)</span>
<span id="cb17-35"><a href="#cb17-35" aria-hidden="true" tabindex="-1"></a>_ <span class="op">=</span> plt.colorbar()</span></code></pre></div>
<div class="output stream stderr">
<pre><code>&lt;ipython-input-17-f79863e904a6&gt;:18: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  example_float = example.astype(np.float)
</code></pre>
</div>
<div class="output display_data">
<p><img
src="vertopal_3774d5ea267f4fc19b2d8a53a2ba506b/fb722fa6af243ab47e2e4c62ffe847c7ddf51999.png" /></p>
</div>
</div>
<div class="cell code" data-deletable="false" data-editable="false"
id="ia-AqqDsciFH"
data-nbgrader="{&quot;cell_type&quot;:&quot;code&quot;,&quot;checksum&quot;:&quot;ee626d21f249b0cc04f73acd1bfd0192&quot;,&quot;grade&quot;:true,&quot;grade_id&quot;:&quot;cell-dab2b2dd97bd278f&quot;,&quot;locked&quot;:true,&quot;points&quot;:5,&quot;schema_version&quot;:3,&quot;solution&quot;:false}">
<div class="sourceCode" id="cb19"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="cf">assert</span> blurred_image.shape <span class="op">==</span> example.shape</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a><span class="cf">assert</span> filtered_image.shape <span class="op">==</span> example.shape</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a><span class="cf">assert</span> my_filter.shape <span class="op">==</span> (<span class="dv">3</span>,<span class="dv">3</span>)</span></code></pre></div>
</div>
<section id="feedforward-nn-versus-cnn" class="cell markdown"
id="a2cV84o4ciFH">
<h3>Feedforward NN versus CNN</h3>
<p>Let's build two models -- a dense feed-forward NN and a convolutional
NN. We'll train each on the MNIST training set, test them on the test
set, and compare performance results (accuracy). Because the test data
set is balanced (approximately 1000 samples of each of the 10 digits),
accuracy is a reasonably good metric so we'll just use that rather than
F-score, for simplicity.</p>
<p>In an effort have an apples-to-apples comparison, we'll use the same
number of layers in both networks, and nearly the same number of total
model parameters.</p>
<p><strong>We'll start by creating a the feedforward network--one with
two hidden layers plus an output layer.</strong></p>
</section>
<div class="cell code"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
data-deletable="false" id="KqONXhTGciFH"
data-nbgrader="{&quot;cell_type&quot;:&quot;code&quot;,&quot;checksum&quot;:&quot;488b3397640cdf6f029e5df580de2466&quot;,&quot;grade&quot;:false,&quot;grade_id&quot;:&quot;cell-dd8d2962acc9833c&quot;,&quot;locked&quot;:false,&quot;schema_version&quot;:3,&quot;solution&quot;:true}"
data-outputId="ad06fff0-e748-490d-9ae8-a08dda3c07c5">
<div class="sourceCode" id="cb20"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a list of Keras layers, calling it &quot;ff_layers&quot;, and use the</span></span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Keras Sequential class to create a feedforward NN model, as you</span></span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a><span class="co"># did in Activity 5a.</span></span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Your model should have two hidden Dense layers and an output Dense layer.</span></span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Use the &quot;relu&quot; activation function for the hidden layers. Other point-wise</span></span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a><span class="co"># non-linear activation function might work fairly well, but ReLU is the</span></span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a><span class="co"># most common because of its computational efficiency as well as its</span></span>
<span id="cb20-10"><a href="#cb20-10" aria-hidden="true" tabindex="-1"></a><span class="co"># effectiveness.</span></span>
<span id="cb20-11"><a href="#cb20-11" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb20-12"><a href="#cb20-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Use 25 neurons in each of the hidden layers.</span></span>
<span id="cb20-13"><a href="#cb20-13" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb20-14"><a href="#cb20-14" aria-hidden="true" tabindex="-1"></a><span class="co"># This is a classification task with 10 output classes so select the output</span></span>
<span id="cb20-15"><a href="#cb20-15" aria-hidden="true" tabindex="-1"></a><span class="co"># layer&#39;s activation function accordingly. Review the reading material or lecture</span></span>
<span id="cb20-16"><a href="#cb20-16" aria-hidden="true" tabindex="-1"></a><span class="co"># slides from the first deep learning lecture, 5a, if you don&#39;t recall</span></span>
<span id="cb20-17"><a href="#cb20-17" aria-hidden="true" tabindex="-1"></a><span class="co"># what it should be or why.</span></span>
<span id="cb20-18"><a href="#cb20-18" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb20-19"><a href="#cb20-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Since the input data (image) is a matrix, you&#39;ll need to additional layers</span></span>
<span id="cb20-20"><a href="#cb20-20" aria-hidden="true" tabindex="-1"></a><span class="co"># at the beginning of your &quot;ff_layers&quot; list.</span></span>
<span id="cb20-21"><a href="#cb20-21" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. An Input() layer, that tells the model what shape the input samples</span></span>
<span id="cb20-22"><a href="#cb20-22" aria-hidden="true" tabindex="-1"></a><span class="co">#    will be, (28, 28, 1).</span></span>
<span id="cb20-23"><a href="#cb20-23" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. A Flatten layer, to convert that image/matrix into a vector, which</span></span>
<span id="cb20-24"><a href="#cb20-24" aria-hidden="true" tabindex="-1"></a><span class="co">#    is the what the subsequent Dense layer expects.</span></span>
<span id="cb20-25"><a href="#cb20-25" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb20-26"><a href="#cb20-26" aria-hidden="true" tabindex="-1"></a><span class="co"># Also, add a Dropout layer after each hidden Dense layer, for regularization.</span></span>
<span id="cb20-27"><a href="#cb20-27" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb20-28"><a href="#cb20-28" aria-hidden="true" tabindex="-1"></a><span class="co"># Finally, save the resulting Sequential model as &quot;ff_model&quot;</span></span>
<span id="cb20-29"><a href="#cb20-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-30"><a href="#cb20-30" aria-hidden="true" tabindex="-1"></a><span class="co"># YOUR CODE HERE</span></span>
<span id="cb20-31"><a href="#cb20-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-32"><a href="#cb20-32" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> keras.models <span class="im">import</span> Sequential</span>
<span id="cb20-33"><a href="#cb20-33" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> keras.layers <span class="im">import</span> Input, Flatten, Dense, Dropout</span>
<span id="cb20-34"><a href="#cb20-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-35"><a href="#cb20-35" aria-hidden="true" tabindex="-1"></a>ff_layers <span class="op">=</span> [Input(shape<span class="op">=</span>(<span class="dv">28</span>,<span class="dv">28</span>,<span class="dv">1</span>)),             Flatten(),             Dense(<span class="dv">25</span>, activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>),             Dropout(<span class="fl">0.5</span>),             Dense(<span class="dv">25</span>, activation<span class="op">=</span><span class="st">&#39;relu&#39;</span>),             Dropout(<span class="fl">0.5</span>),             Dense(<span class="dv">10</span>, activation<span class="op">=</span><span class="st">&#39;softmax&#39;</span>)]</span>
<span id="cb20-36"><a href="#cb20-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-37"><a href="#cb20-37" aria-hidden="true" tabindex="-1"></a>ff_model <span class="op">=</span> Sequential(ff_layers)</span>
<span id="cb20-38"><a href="#cb20-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-39"><a href="#cb20-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-40"><a href="#cb20-40" aria-hidden="true" tabindex="-1"></a><span class="co"># raise NotImplementedError()</span></span>
<span id="cb20-41"><a href="#cb20-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-42"><a href="#cb20-42" aria-hidden="true" tabindex="-1"></a>ff_model.summary()</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Model: &quot;sequential&quot;
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 flatten (Flatten)           (None, 784)               0         
                                                                 
 dense (Dense)               (None, 25)                19625     
                                                                 
 dropout (Dropout)           (None, 25)                0         
                                                                 
 dense_1 (Dense)             (None, 25)                650       
                                                                 
 dropout_1 (Dropout)         (None, 25)                0         
                                                                 
 dense_2 (Dense)             (None, 10)                260       
                                                                 
=================================================================
Total params: 20,535
Trainable params: 20,535
Non-trainable params: 0
_________________________________________________________________
</code></pre>
</div>
</div>
<div class="cell markdown" id="XqqK6KRociFI">
<p>Look at the output <strong>above</strong>, from
<code>ff_model.summary()</code>, and take note of the <strong>total
number of model parameters</strong>.</p>
</div>
<div class="cell code" data-deletable="false" data-editable="false"
id="9rj8DqXzciFI"
data-nbgrader="{&quot;cell_type&quot;:&quot;code&quot;,&quot;checksum&quot;:&quot;a8bc339ed2ed5a9e26fd2303ea6f357d&quot;,&quot;grade&quot;:true,&quot;grade_id&quot;:&quot;cell-b9330f9b40580d4b&quot;,&quot;locked&quot;:true,&quot;points&quot;:5,&quot;schema_version&quot;:3,&quot;solution&quot;:false}">
<div class="sourceCode" id="cb22"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="cf">assert</span> <span class="bu">len</span>(ff_layers) <span class="op">==</span> <span class="dv">7</span></span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>target_type <span class="op">=</span> [Flatten, Dense, Dropout, Dense, Dropout, Dense]</span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> l, tt <span class="kw">in</span> <span class="bu">zip</span>(ff_model.layers, target_type):</span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">assert</span> <span class="bu">isinstance</span>(l, tt)</span></code></pre></div>
</div>
<section id="evaluating-your-test-or-validation-set-while-training"
class="cell markdown" id="bGA89YDBciFI">
<h3>Evaluating your test or validation set while training</h3>
<p>In previous notebooks we passed our training data to
<code>Model.fit</code>, which trained for a specified number of epochs.
Then we plotted the training set loss (and/or metrics) as a function of
epochs, allowing us to see the dynamics of the model's convergence
toward a solution.</p>
<p>In this notebook we'll also pass our test data to
<code>Model.fit</code>. The Model object is smart. It will use only the
training data for fitting, but it will also compute the loss and metric
functions for the test data, at the end of each training epoch.
Afterwards, we can plot the loss and metrics for both the training data
and for the test data.</p>
</section>
<div class="cell code"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:1000}"
id="U-mTqx_YciFJ" data-outputId="c7e094bf-d839-4dd3-d30f-3c7cc18eb353">
<div class="sourceCode" id="cb23"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="co">## Let&#39;s train the model and plot the training loss curve</span></span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a><span class="co"># We&#39;ll train for 20 epochs. If you change model parameters/hyperparameters above,</span></span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a><span class="co"># and the model&#39;s loss curve hasn&#39;t flattened (approximately) after 20 epochs, you</span></span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a><span class="co"># can increase the number of training epochs.</span></span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a>ff_model.<span class="bu">compile</span>(optimizer<span class="op">=</span><span class="st">&quot;adam&quot;</span>, loss<span class="op">=</span><span class="st">&#39;sparse_categorical_crossentropy&#39;</span>, metrics<span class="op">=</span>[<span class="st">&#39;accuracy&#39;</span>])</span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a>n_epochs <span class="op">=</span> <span class="dv">20</span></span>
<span id="cb23-9"><a href="#cb23-9" aria-hidden="true" tabindex="-1"></a>history <span class="op">=</span> ff_model.fit(x_train, y_train, epochs<span class="op">=</span>n_epochs, validation_data<span class="op">=</span>(x_test, y_test))</span>
<span id="cb23-10"><a href="#cb23-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-11"><a href="#cb23-11" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">5</span>))</span>
<span id="cb23-12"><a href="#cb23-12" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">1</span>)</span>
<span id="cb23-13"><a href="#cb23-13" aria-hidden="true" tabindex="-1"></a>plt.plot(np.arange(<span class="dv">1</span>, n_epochs<span class="op">+</span><span class="dv">1</span>), history.history[<span class="st">&#39;loss&#39;</span>], label<span class="op">=</span><span class="st">&#39;Train set&#39;</span>)</span>
<span id="cb23-14"><a href="#cb23-14" aria-hidden="true" tabindex="-1"></a>plt.plot(np.arange(<span class="dv">1</span>, n_epochs<span class="op">+</span><span class="dv">1</span>), history.history[<span class="st">&#39;val_loss&#39;</span>], label<span class="op">=</span><span class="st">&#39;Test set&#39;</span>)</span>
<span id="cb23-15"><a href="#cb23-15" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb23-16"><a href="#cb23-16" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&#39;Epoch&#39;</span>)</span>
<span id="cb23-17"><a href="#cb23-17" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&#39;Loss&#39;</span>)</span>
<span id="cb23-18"><a href="#cb23-18" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>)</span>
<span id="cb23-19"><a href="#cb23-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-20"><a href="#cb23-20" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">2</span>)</span>
<span id="cb23-21"><a href="#cb23-21" aria-hidden="true" tabindex="-1"></a>plt.plot(np.arange(<span class="dv">1</span>, n_epochs<span class="op">+</span><span class="dv">1</span>), history.history[<span class="st">&#39;accuracy&#39;</span>], label<span class="op">=</span><span class="st">&#39;Train set&#39;</span>)</span>
<span id="cb23-22"><a href="#cb23-22" aria-hidden="true" tabindex="-1"></a>plt.plot(np.arange(<span class="dv">1</span>, n_epochs<span class="op">+</span><span class="dv">1</span>), history.history[<span class="st">&#39;val_accuracy&#39;</span>], label<span class="op">=</span><span class="st">&#39;Test set&#39;</span>)</span>
<span id="cb23-23"><a href="#cb23-23" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb23-24"><a href="#cb23-24" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&#39;Epoch&#39;</span>)</span>
<span id="cb23-25"><a href="#cb23-25" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&#39;Accuracy&#39;</span>)</span>
<span id="cb23-26"><a href="#cb23-26" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>)</span>
<span id="cb23-27"><a href="#cb23-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-28"><a href="#cb23-28" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;</span><span class="ch">\n</span><span class="ss">Accuracy on the final epoch of training was </span><span class="sc">{</span><span class="dv">100</span><span class="op">*</span>history<span class="sc">.</span>history[<span class="st">&#39;accuracy&#39;</span>][<span class="op">-</span><span class="dv">1</span>]<span class="sc">:0.2f}</span><span class="ss">%&quot;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Epoch 1/20
1875/1875 [==============================] - 7s 3ms/step - loss: 3.0842 - accuracy: 0.1123 - val_loss: 2.3039 - val_accuracy: 0.1137
Epoch 2/20
1875/1875 [==============================] - 5s 2ms/step - loss: 2.3019 - accuracy: 0.1124 - val_loss: 2.3039 - val_accuracy: 0.1138
Epoch 3/20
1875/1875 [==============================] - 5s 3ms/step - loss: 2.3015 - accuracy: 0.1124 - val_loss: 2.3039 - val_accuracy: 0.1136
Epoch 4/20
1875/1875 [==============================] - 5s 2ms/step - loss: 2.3019 - accuracy: 0.1124 - val_loss: 2.3040 - val_accuracy: 0.1136
Epoch 5/20
1875/1875 [==============================] - 5s 3ms/step - loss: 2.3029 - accuracy: 0.1124 - val_loss: 2.3041 - val_accuracy: 0.1135
Epoch 6/20
1875/1875 [==============================] - 6s 3ms/step - loss: 2.3013 - accuracy: 0.1124 - val_loss: 2.3039 - val_accuracy: 0.1135
Epoch 7/20
1875/1875 [==============================] - 5s 2ms/step - loss: 2.3019 - accuracy: 0.1124 - val_loss: 2.3018 - val_accuracy: 0.1135
Epoch 8/20
1875/1875 [==============================] - 5s 3ms/step - loss: 2.3014 - accuracy: 0.1124 - val_loss: 2.3018 - val_accuracy: 0.1135
Epoch 9/20
1875/1875 [==============================] - 5s 3ms/step - loss: 2.3013 - accuracy: 0.1124 - val_loss: 2.3018 - val_accuracy: 0.1135
Epoch 10/20
1875/1875 [==============================] - 6s 3ms/step - loss: 2.3013 - accuracy: 0.1124 - val_loss: 2.3021 - val_accuracy: 0.1135
Epoch 11/20
1875/1875 [==============================] - 9s 5ms/step - loss: 2.3013 - accuracy: 0.1124 - val_loss: 2.3019 - val_accuracy: 0.1135
Epoch 12/20
1875/1875 [==============================] - 5s 2ms/step - loss: 2.3013 - accuracy: 0.1124 - val_loss: 2.3020 - val_accuracy: 0.1135
Epoch 13/20
1875/1875 [==============================] - 6s 3ms/step - loss: 2.3013 - accuracy: 0.1124 - val_loss: 2.3020 - val_accuracy: 0.1135
Epoch 14/20
1875/1875 [==============================] - 5s 2ms/step - loss: 2.3014 - accuracy: 0.1124 - val_loss: 2.3019 - val_accuracy: 0.1135
Epoch 15/20
1875/1875 [==============================] - 5s 3ms/step - loss: 2.3014 - accuracy: 0.1124 - val_loss: 2.3019 - val_accuracy: 0.1135
Epoch 16/20
1875/1875 [==============================] - 5s 3ms/step - loss: 2.3013 - accuracy: 0.1124 - val_loss: 2.3019 - val_accuracy: 0.1135
Epoch 17/20
1875/1875 [==============================] - 5s 2ms/step - loss: 2.3013 - accuracy: 0.1124 - val_loss: 2.3020 - val_accuracy: 0.1135
Epoch 18/20
1875/1875 [==============================] - 6s 3ms/step - loss: 2.3013 - accuracy: 0.1124 - val_loss: 2.3020 - val_accuracy: 0.1135
Epoch 19/20
1875/1875 [==============================] - 4s 2ms/step - loss: 2.3013 - accuracy: 0.1124 - val_loss: 2.3019 - val_accuracy: 0.1135
Epoch 20/20
1875/1875 [==============================] - 5s 3ms/step - loss: 2.3013 - accuracy: 0.1124 - val_loss: 2.3018 - val_accuracy: 0.1135

Accuracy on the final epoch of training was 11.24%
</code></pre>
</div>
<div class="output display_data">
<p><img
src="vertopal_3774d5ea267f4fc19b2d8a53a2ba506b/769c35169eea4cd7d44f4e6b6417c314cbd48232.png" /></p>
</div>
</div>
<div class="cell code"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="kNys7yxDciFJ"
data-nbgrader="{&quot;grade&quot;:false,&quot;grade_id&quot;:&quot;cell-045361b2e3f23134&quot;,&quot;locked&quot;:false,&quot;schema_version&quot;:3,&quot;solution&quot;:false}"
data-outputId="07c2eede-cfac-4125-dd58-2887a97133b0">
<div class="sourceCode" id="cb25"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Let&#39;s assess our FF model&#39;s performance on the test set</span></span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a>ff_scores <span class="op">=</span> ff_model.evaluate(x_test, y_test)</span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;</span><span class="ch">\n</span><span class="ss">The fully-connected feedforward model achieves an accuracy of </span><span class="sc">{</span>ff_scores[<span class="dv">1</span>]<span class="op">*</span><span class="dv">100</span><span class="sc">:.2f}</span><span class="ss">% on the test data.&quot;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>313/313 [==============================] - 1s 2ms/step - loss: 2.3018 - accuracy: 0.1135

The fully-connected feedforward model achieves an accuracy of 11.35% on the test data.
</code></pre>
</div>
</div>
<section id="result-from-the-feedforward-nn" class="cell markdown"
id="xhPezi1DciFJ">
<h3>Result from the feedforward NN</h3>
<p><strong>You may find that the accuracy on the test set is higher than
reported for the training set! But it's really not. Let us
explain...</strong></p>
<p>We used dropout during training, which helps with model
regularization (and generalization) but reduces performance when in use
(i.e., during training). <strong>When we use the <code>evaluate()</code>
method, the dropout layers are "turned off."</strong> Similarly,
<code>fit</code> does not apply dropout to the test/validation set, only
to the training set. If we were to put our training set through the
trained model, without dropout (that is, by using <code>evaluate</code>)
we would get accuracy scores like those of the test data, and likely a
little bit higher.</p>
<p>What's a good accuracy for our model? Is 50% good?</p>
<p>Something to consider is that we have 10 classes - does that change
your answer? What would random guessing's accuracy be?</p>
<p>Based on your answer to the above questions, is your simple model
good?</p>
<p><strong>Let's see if we can do better. In the next section, we'll
build a convolutional neural network. You'll need to use <a
href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D">Conv2D</a>
and <a
href="https://www.tensorflow.org/api_docs/python/tf/keras/layers/MaxPool2D">MaxPool2D</a>
layers from Keras.</strong></p>
</section>
<div class="cell code"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
data-deletable="false" id="_rJ1SHG7ciFK"
data-nbgrader="{&quot;cell_type&quot;:&quot;code&quot;,&quot;checksum&quot;:&quot;ee25e18eda6ad104129ee745ae1a1401&quot;,&quot;grade&quot;:false,&quot;grade_id&quot;:&quot;cell-960d34277a5b576e&quot;,&quot;locked&quot;:false,&quot;schema_version&quot;:3,&quot;solution&quot;:true}"
data-outputId="9d5165ba-2086-448f-9b8c-27424b768b23">
<div class="sourceCode" id="cb27"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Now you&#39;ll build a CNN that has the same number of layers as the</span></span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a><span class="co"># feedforward NN, and a comparable number of model parameters.</span></span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a><span class="co"># The CNN&#39;s convolutional and pooling layers will steadily reduce the</span></span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a><span class="co"># number of neurons/outputs in the vertical and horizontal dimensions</span></span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a><span class="co"># while increasing the number of channels (the &quot;depth&quot; dimension).</span></span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb27-8"><a href="#cb27-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Your CNN model should be defined by a list of layers, called &quot;cnn_layers&quot;,</span></span>
<span id="cb27-9"><a href="#cb27-9" aria-hidden="true" tabindex="-1"></a><span class="co"># organized as such:</span></span>
<span id="cb27-10"><a href="#cb27-10" aria-hidden="true" tabindex="-1"></a><span class="co"># [Input(),</span></span>
<span id="cb27-11"><a href="#cb27-11" aria-hidden="true" tabindex="-1"></a><span class="co">#  Conv2D(),</span></span>
<span id="cb27-12"><a href="#cb27-12" aria-hidden="true" tabindex="-1"></a><span class="co">#  MaxPool2D(),</span></span>
<span id="cb27-13"><a href="#cb27-13" aria-hidden="true" tabindex="-1"></a><span class="co">#  Conv2D(),</span></span>
<span id="cb27-14"><a href="#cb27-14" aria-hidden="true" tabindex="-1"></a><span class="co">#  MaxPool2D(),</span></span>
<span id="cb27-15"><a href="#cb27-15" aria-hidden="true" tabindex="-1"></a><span class="co">#  Flatten(),</span></span>
<span id="cb27-16"><a href="#cb27-16" aria-hidden="true" tabindex="-1"></a><span class="co">#  Dense()]</span></span>
<span id="cb27-17"><a href="#cb27-17" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb27-18"><a href="#cb27-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Create that list such that the first and second Conv2D layers have 16 and</span></span>
<span id="cb27-19"><a href="#cb27-19" aria-hidden="true" tabindex="-1"></a><span class="co"># 32 channels, respectively. Use a (3, 3)-shaped convolutional kernel</span></span>
<span id="cb27-20"><a href="#cb27-20" aria-hidden="true" tabindex="-1"></a><span class="co"># for both Conv2D layers, along with &quot;same&quot; padding and &quot;relu&quot; activation.</span></span>
<span id="cb27-21"><a href="#cb27-21" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb27-22"><a href="#cb27-22" aria-hidden="true" tabindex="-1"></a><span class="co"># You can use the defaults for the MaxPool2D layers (pooling over a 2x2</span></span>
<span id="cb27-23"><a href="#cb27-23" aria-hidden="true" tabindex="-1"></a><span class="co"># area, which thus halves the width and height dimensions).</span></span>
<span id="cb27-24"><a href="#cb27-24" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb27-25"><a href="#cb27-25" aria-hidden="true" tabindex="-1"></a><span class="co"># You&#39;ll then flatten the output of the second/last pooling layer, and</span></span>
<span id="cb27-26"><a href="#cb27-26" aria-hidden="true" tabindex="-1"></a><span class="co"># send that to a Dense output layer of 10 neurons. Be sure to use the</span></span>
<span id="cb27-27"><a href="#cb27-27" aria-hidden="true" tabindex="-1"></a><span class="co"># appropriate activation function for the output layer, as you did for</span></span>
<span id="cb27-28"><a href="#cb27-28" aria-hidden="true" tabindex="-1"></a><span class="co"># the feedforward NN.</span></span>
<span id="cb27-29"><a href="#cb27-29" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb27-30"><a href="#cb27-30" aria-hidden="true" tabindex="-1"></a><span class="co"># Dropout doesn&#39;t provide much regularization support in CNN models, as</span></span>
<span id="cb27-31"><a href="#cb27-31" aria-hidden="true" tabindex="-1"></a><span class="co"># the constraints imposed by architecture itself provides that. So we</span></span>
<span id="cb27-32"><a href="#cb27-32" aria-hidden="true" tabindex="-1"></a><span class="co"># won&#39;t use Dropout layers in the CNN.</span></span>
<span id="cb27-33"><a href="#cb27-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-34"><a href="#cb27-34" aria-hidden="true" tabindex="-1"></a><span class="co"># Create your CNN model using Sequential, and save it as &quot;cnn_model&quot;.</span></span>
<span id="cb27-35"><a href="#cb27-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-36"><a href="#cb27-36" aria-hidden="true" tabindex="-1"></a><span class="co"># YOUR CODE HERE</span></span>
<span id="cb27-37"><a href="#cb27-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-38"><a href="#cb27-38" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the CNN model</span></span>
<span id="cb27-39"><a href="#cb27-39" aria-hidden="true" tabindex="-1"></a>cnn_layers <span class="op">=</span> [</span>
<span id="cb27-40"><a href="#cb27-40" aria-hidden="true" tabindex="-1"></a>    Input(shape<span class="op">=</span>(<span class="dv">28</span>, <span class="dv">28</span>, <span class="dv">1</span>)),</span>
<span id="cb27-41"><a href="#cb27-41" aria-hidden="true" tabindex="-1"></a>    Conv2D(<span class="dv">16</span>, (<span class="dv">3</span>, <span class="dv">3</span>), padding<span class="op">=</span><span class="st">&quot;same&quot;</span>, activation<span class="op">=</span><span class="st">&quot;relu&quot;</span>),</span>
<span id="cb27-42"><a href="#cb27-42" aria-hidden="true" tabindex="-1"></a>    MaxPool2D(),</span>
<span id="cb27-43"><a href="#cb27-43" aria-hidden="true" tabindex="-1"></a>    Conv2D(<span class="dv">32</span>, (<span class="dv">3</span>, <span class="dv">3</span>), padding<span class="op">=</span><span class="st">&quot;same&quot;</span>, activation<span class="op">=</span><span class="st">&quot;relu&quot;</span>),</span>
<span id="cb27-44"><a href="#cb27-44" aria-hidden="true" tabindex="-1"></a>    MaxPool2D(),</span>
<span id="cb27-45"><a href="#cb27-45" aria-hidden="true" tabindex="-1"></a>    Flatten(),</span>
<span id="cb27-46"><a href="#cb27-46" aria-hidden="true" tabindex="-1"></a>    Dense(<span class="dv">10</span>, activation<span class="op">=</span><span class="st">&quot;softmax&quot;</span>)</span>
<span id="cb27-47"><a href="#cb27-47" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb27-48"><a href="#cb27-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-49"><a href="#cb27-49" aria-hidden="true" tabindex="-1"></a><span class="co"># Create the CNN model using Sequential</span></span>
<span id="cb27-50"><a href="#cb27-50" aria-hidden="true" tabindex="-1"></a>cnn_model <span class="op">=</span> Sequential(cnn_layers)</span>
<span id="cb27-51"><a href="#cb27-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-52"><a href="#cb27-52" aria-hidden="true" tabindex="-1"></a><span class="co"># raise NotImplementedError()</span></span>
<span id="cb27-53"><a href="#cb27-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-54"><a href="#cb27-54" aria-hidden="true" tabindex="-1"></a>cnn_model.summary()</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Model: &quot;sequential_1&quot;
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 conv2d (Conv2D)             (None, 28, 28, 16)        160       
                                                                 
 max_pooling2d (MaxPooling2D  (None, 14, 14, 16)       0         
 )                                                               
                                                                 
 conv2d_1 (Conv2D)           (None, 14, 14, 32)        4640      
                                                                 
 max_pooling2d_1 (MaxPooling  (None, 7, 7, 32)         0         
 2D)                                                             
                                                                 
 flatten_1 (Flatten)         (None, 1568)              0         
                                                                 
 dense_3 (Dense)             (None, 10)                15690     
                                                                 
=================================================================
Total params: 20,490
Trainable params: 20,490
Non-trainable params: 0
_________________________________________________________________
</code></pre>
</div>
</div>
<div class="cell markdown" id="nelxezS_ciFK">
<p>Look at the output <strong>above</strong>, from
<code>cnn_model.summary()</code>, and take note of the <strong>total
number of model parameters</strong>.</p>
</div>
<div class="cell code" data-deletable="false" data-editable="false"
id="2FwMPoOSciFK"
data-nbgrader="{&quot;cell_type&quot;:&quot;code&quot;,&quot;checksum&quot;:&quot;34fac23b1e3643b50ef90e676bb87d9c&quot;,&quot;grade&quot;:true,&quot;grade_id&quot;:&quot;cell-44d2df9e1f2284ec&quot;,&quot;locked&quot;:true,&quot;points&quot;:5,&quot;schema_version&quot;:3,&quot;solution&quot;:false}">
<div class="sourceCode" id="cb29"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="cf">assert</span> <span class="bu">len</span>(cnn_layers) <span class="op">==</span> <span class="dv">7</span></span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a>target_type <span class="op">=</span> [Conv2D, MaxPool2D, Conv2D, MaxPool2D, Flatten, Dense]</span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> l, tt <span class="kw">in</span> <span class="bu">zip</span>(cnn_model.layers, target_type):</span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">assert</span> <span class="bu">isinstance</span>(l, tt)</span></code></pre></div>
</div>
<div class="cell code"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:579}"
id="cvrg8gHSciFL" data-outputId="620f81bc-f507-442f-916e-bb7d942c1d9c">
<div class="sourceCode" id="cb30"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Now we&#39;ll train the CNN model.</span></span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Because the 2D architecture of the CNN constrains the model to learn patterns</span></span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a><span class="co"># that exist in 2D space (e.g., nearby pixels are more likely to exhibit some</span></span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true" tabindex="-1"></a><span class="co"># connectedness/pattern than distant pixles) the model learns much more quickly</span></span>
<span id="cb30-6"><a href="#cb30-6" aria-hidden="true" tabindex="-1"></a><span class="co"># (that is, with fewer training epochs). So we&#39;ll only train for 3 epochs this time.</span></span>
<span id="cb30-7"><a href="#cb30-7" aria-hidden="true" tabindex="-1"></a><span class="co"># You can increase the number of epochs if you&#39;d like.</span></span>
<span id="cb30-8"><a href="#cb30-8" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb30-9"><a href="#cb30-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Also, the model expects the input samples to have a &quot;channel&quot; dimension, e.g.,</span></span>
<span id="cb30-10"><a href="#cb30-10" aria-hidden="true" tabindex="-1"></a><span class="co"># three channels (red/green/blue) for color images, 1 channel for grayscale images.</span></span>
<span id="cb30-11"><a href="#cb30-11" aria-hidden="true" tabindex="-1"></a><span class="co"># So we&#39;ll reshape our training images from (n_samples, 28, 28) to</span></span>
<span id="cb30-12"><a href="#cb30-12" aria-hidden="true" tabindex="-1"></a><span class="co"># (n_samples, 28, 28, 1).</span></span>
<span id="cb30-13"><a href="#cb30-13" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb30-14"><a href="#cb30-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Note that we used &#39;sparse_categorical_crossentropy&#39; as the loss function,</span></span>
<span id="cb30-15"><a href="#cb30-15" aria-hidden="true" tabindex="-1"></a><span class="co"># which is typical for classification tasks with a softmax output activation function.</span></span>
<span id="cb30-16"><a href="#cb30-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-17"><a href="#cb30-17" aria-hidden="true" tabindex="-1"></a>cnn_model.<span class="bu">compile</span>(optimizer<span class="op">=</span><span class="st">&quot;adam&quot;</span>, loss<span class="op">=</span><span class="st">&#39;sparse_categorical_crossentropy&#39;</span>, metrics<span class="op">=</span>[<span class="st">&#39;accuracy&#39;</span>])</span>
<span id="cb30-18"><a href="#cb30-18" aria-hidden="true" tabindex="-1"></a>n_epochs <span class="op">=</span> <span class="dv">3</span></span>
<span id="cb30-19"><a href="#cb30-19" aria-hidden="true" tabindex="-1"></a>history <span class="op">=</span> cnn_model.fit(x_train.reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">28</span>, <span class="dv">28</span> ,<span class="dv">1</span>), y_train, epochs<span class="op">=</span>n_epochs,</span>
<span id="cb30-20"><a href="#cb30-20" aria-hidden="true" tabindex="-1"></a>                        validation_data<span class="op">=</span>(x_test.reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">28</span>, <span class="dv">28</span> ,<span class="dv">1</span>), y_test))</span>
<span id="cb30-21"><a href="#cb30-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-22"><a href="#cb30-22" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">5</span>))</span>
<span id="cb30-23"><a href="#cb30-23" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">1</span>)</span>
<span id="cb30-24"><a href="#cb30-24" aria-hidden="true" tabindex="-1"></a>plt.plot(np.arange(<span class="dv">1</span>, n_epochs<span class="op">+</span><span class="dv">1</span>), history.history[<span class="st">&#39;loss&#39;</span>], label<span class="op">=</span><span class="st">&#39;Train set&#39;</span>)</span>
<span id="cb30-25"><a href="#cb30-25" aria-hidden="true" tabindex="-1"></a>plt.plot(np.arange(<span class="dv">1</span>, n_epochs<span class="op">+</span><span class="dv">1</span>), history.history[<span class="st">&#39;val_loss&#39;</span>], label<span class="op">=</span><span class="st">&#39;Test set&#39;</span>)</span>
<span id="cb30-26"><a href="#cb30-26" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb30-27"><a href="#cb30-27" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&#39;Epoch&#39;</span>)</span>
<span id="cb30-28"><a href="#cb30-28" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&#39;Loss&#39;</span>)</span>
<span id="cb30-29"><a href="#cb30-29" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>)</span>
<span id="cb30-30"><a href="#cb30-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-31"><a href="#cb30-31" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">2</span>)</span>
<span id="cb30-32"><a href="#cb30-32" aria-hidden="true" tabindex="-1"></a>plt.plot(np.arange(<span class="dv">1</span>, n_epochs<span class="op">+</span><span class="dv">1</span>), history.history[<span class="st">&#39;accuracy&#39;</span>], label<span class="op">=</span><span class="st">&#39;Train set&#39;</span>)</span>
<span id="cb30-33"><a href="#cb30-33" aria-hidden="true" tabindex="-1"></a>plt.plot(np.arange(<span class="dv">1</span>, n_epochs<span class="op">+</span><span class="dv">1</span>), history.history[<span class="st">&#39;val_accuracy&#39;</span>], label<span class="op">=</span><span class="st">&#39;Test set&#39;</span>)</span>
<span id="cb30-34"><a href="#cb30-34" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb30-35"><a href="#cb30-35" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&#39;Epoch&#39;</span>)</span>
<span id="cb30-36"><a href="#cb30-36" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&#39;Accuracy&#39;</span>)</span>
<span id="cb30-37"><a href="#cb30-37" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>)</span>
<span id="cb30-38"><a href="#cb30-38" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;</span><span class="ch">\n</span><span class="ss">Accuracy on the final epoch of training was </span><span class="sc">{</span><span class="dv">100</span><span class="op">*</span>history<span class="sc">.</span>history[<span class="st">&#39;accuracy&#39;</span>][<span class="op">-</span><span class="dv">1</span>]<span class="sc">:0.2f}</span><span class="ss">%&quot;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Epoch 1/3
1875/1875 [==============================] - 46s 24ms/step - loss: 0.5367 - accuracy: 0.9333 - val_loss: 0.0842 - val_accuracy: 0.9728
Epoch 2/3
1875/1875 [==============================] - 46s 25ms/step - loss: 0.0820 - accuracy: 0.9759 - val_loss: 0.0722 - val_accuracy: 0.9780
Epoch 3/3
1875/1875 [==============================] - 44s 24ms/step - loss: 0.0613 - accuracy: 0.9809 - val_loss: 0.0557 - val_accuracy: 0.9829

Accuracy on the final epoch of training was 98.09%
</code></pre>
</div>
<div class="output display_data">
<p><img
src="vertopal_3774d5ea267f4fc19b2d8a53a2ba506b/5f3983b5bf68f1c6a56c88a3cad8f0e177cacb8a.png" /></p>
</div>
</div>
<div class="cell code"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="nBVOuDPnciFL"
data-nbgrader="{&quot;grade&quot;:false,&quot;grade_id&quot;:&quot;cell-a6157eb6365d54be&quot;,&quot;locked&quot;:false,&quot;schema_version&quot;:3,&quot;solution&quot;:false}"
data-outputId="3b3ac1cb-dda7-4dc4-fe57-2789f9492c62">
<div class="sourceCode" id="cb32"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Let&#39;s assess our CNN model&#39;s performance on the test set</span></span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a>cnn_scores <span class="op">=</span> cnn_model.evaluate(x_test.reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">28</span>, <span class="dv">28</span> ,<span class="dv">1</span>), y_test)</span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-4"><a href="#cb32-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;</span><span class="ch">\n</span><span class="ss">The CNN model achieves an accuracy of </span><span class="sc">{</span>cnn_scores[<span class="dv">1</span>]<span class="op">*</span><span class="dv">100</span><span class="sc">:.2f}</span><span class="ss">% on the test data.&quot;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>313/313 [==============================] - 2s 8ms/step - loss: 0.0557 - accuracy: 0.9829

The CNN model achieves an accuracy of 98.29% on the test data.
</code></pre>
</div>
</div>
<section id="results-from-the-cnn-model" class="cell markdown"
id="X-jl-RZpciFL">
<h3>Results from the CNN model</h3>
<p>If all went as planned, you saw notably higher accuracy from the CNN
than from the feedforward network, <strong>despite both networks having
the same number of layers and nearly the same number of model
parameters. It also converged much faster!</strong></p>
<p>We didn't use dropout this time, so the "artificial" situation in
which test set accuracy appears to be notably higher than training set
accuracy should go away. However, even without dropout, the test set
accuracy is often reported as being higher in <em>early</em> epochs, but
this is for a different reason. The accuracy reported for a training set
of a given epoch is the average of all batch accuracies <em>while the
model was learning</em>, such that early batches did worse than later
batches, within that epoch. The test set is not scored until after the
training epoch is complete, so the model is "better" at that moment in
time, and thus the test set accuracy score is higher.</p>
<p><strong>Feel free to modify the FF and/or CNN networks</strong> --
increasing or decreasing number of neurons, numbers of layers, and types
of activation functions. <strong>Just be sure that your asserts/test
cells pass after a fresh run of your notebook, before turning it
in.</strong></p>
</section>
<div class="cell code" data-deletable="false" data-editable="false"
id="llbiGBmUciFM"
data-nbgrader="{&quot;cell_type&quot;:&quot;code&quot;,&quot;checksum&quot;:&quot;89d58854a6fbaf631d5783b3d8c8df27&quot;,&quot;grade&quot;:true,&quot;grade_id&quot;:&quot;cell-279d9d45069805b8&quot;,&quot;locked&quot;:true,&quot;points&quot;:0,&quot;schema_version&quot;:3,&quot;solution&quot;:false,&quot;task&quot;:false}">
<div class="sourceCode" id="cb34"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="cf">assert</span> cnn_scores[<span class="dv">1</span>] <span class="op">&gt;</span> <span class="fl">0.9</span></span></code></pre></div>
</div>
<section id="play-in-the-sandbox" class="cell markdown"
id="JIvkU8-dciFM">
<h3>Play in the sandbox</h3>
<p>Below you may want to explore the outputs of the two models for a
variety of individual samples (images). With each run, the output
predictions for all 10 classes are plotted, so you can <strong>compare
the "sharpness" of the predicted class probability distribution</strong>
(using the term "probability distribution" loosely) of the CNN versus
the FF model.</p>
</section>
<div class="cell code"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:502}"
id="5lM6wBzCciFM" data-outputId="c652f428-b5ba-422d-e439-f770299e745d">
<div class="sourceCode" id="cb35"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Change this value to test out some samples, and see what</span></span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a><span class="co"># them models&#39; predictions look like.</span></span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a>i <span class="op">=</span> <span class="dv">4563</span>   <span class="co"># Pick any number from 0 to 9999</span></span>
<span id="cb35-5"><a href="#cb35-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-6"><a href="#cb35-6" aria-hidden="true" tabindex="-1"></a>new_example <span class="op">=</span> x_test[i]</span>
<span id="cb35-7"><a href="#cb35-7" aria-hidden="true" tabindex="-1"></a>ff_class_probabilities <span class="op">=</span> ff_model.predict(new_example.reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">28</span>, <span class="dv">28</span>))</span>
<span id="cb35-8"><a href="#cb35-8" aria-hidden="true" tabindex="-1"></a>ff_class_prediction <span class="op">=</span> np.argmax(ff_class_probabilities)</span>
<span id="cb35-9"><a href="#cb35-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-10"><a href="#cb35-10" aria-hidden="true" tabindex="-1"></a>cnn_class_probabilities <span class="op">=</span> cnn_model.predict(new_example.reshape(<span class="op">-</span><span class="dv">1</span>, <span class="dv">28</span>, <span class="dv">28</span>, <span class="dv">1</span>))</span>
<span id="cb35-11"><a href="#cb35-11" aria-hidden="true" tabindex="-1"></a>cnn_class_prediction <span class="op">=</span> np.argmax(cnn_class_probabilities)</span>
<span id="cb35-12"><a href="#cb35-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-13"><a href="#cb35-13" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">5</span>))</span>
<span id="cb35-14"><a href="#cb35-14" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">1</span>)</span>
<span id="cb35-15"><a href="#cb35-15" aria-hidden="true" tabindex="-1"></a>plt.imshow(new_example, cmap<span class="op">=</span><span class="st">&quot;gray&quot;</span>)</span>
<span id="cb35-16"><a href="#cb35-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-17"><a href="#cb35-17" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">2</span>)</span>
<span id="cb35-18"><a href="#cb35-18" aria-hidden="true" tabindex="-1"></a>plt.plot(ff_class_probabilities[<span class="dv">0</span>], <span class="st">&#39;-bs&#39;</span>, label<span class="op">=</span><span class="st">&#39;FF&#39;</span>)</span>
<span id="cb35-19"><a href="#cb35-19" aria-hidden="true" tabindex="-1"></a>plt.plot(ff_class_prediction, np.<span class="bu">max</span>(ff_class_probabilities[<span class="dv">0</span>]), <span class="st">&#39;bs&#39;</span>, markersize<span class="op">=</span><span class="dv">15</span>)</span>
<span id="cb35-20"><a href="#cb35-20" aria-hidden="true" tabindex="-1"></a>plt.plot(cnn_class_probabilities[<span class="dv">0</span>], <span class="st">&#39;-ro&#39;</span>, label<span class="op">=</span><span class="st">&#39;CNN&#39;</span>)</span>
<span id="cb35-21"><a href="#cb35-21" aria-hidden="true" tabindex="-1"></a>plt.plot(cnn_class_prediction, np.<span class="bu">max</span>(cnn_class_probabilities[<span class="dv">0</span>]), <span class="st">&#39;ro&#39;</span>, markersize<span class="op">=</span><span class="dv">15</span>)</span>
<span id="cb35-22"><a href="#cb35-22" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&#39;Class&#39;</span>)</span>
<span id="cb35-23"><a href="#cb35-23" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&#39;Probability&#39;</span>)</span>
<span id="cb35-24"><a href="#cb35-24" aria-hidden="true" tabindex="-1"></a>plt.legend(loc<span class="op">=</span><span class="st">&#39;center right&#39;</span>)</span>
<span id="cb35-25"><a href="#cb35-25" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>)</span>
<span id="cb35-26"><a href="#cb35-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-27"><a href="#cb35-27" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;Feedforward model predicts class </span><span class="sc">{</span>ff_class_prediction<span class="sc">}</span><span class="ss">.&quot;</span>)</span>
<span id="cb35-28"><a href="#cb35-28" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&quot;        CNN model predicts class </span><span class="sc">{</span>cnn_class_prediction<span class="sc">}</span><span class="ss">.&quot;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>1/1 [==============================] - 0s 42ms/step
1/1 [==============================] - 0s 22ms/step
Feedforward model predicts class 1.
        CNN model predicts class 1.
</code></pre>
</div>
<div class="output display_data">
<p><img
src="vertopal_3774d5ea267f4fc19b2d8a53a2ba506b/1ec707d64c3325e0f9a4fd6a4365e97f73bf0f51.png" /></p>
</div>
</div>
<section id="feedback" class="cell markdown" data-deletable="false"
data-editable="false" id="mt10v8z3ciFN"
data-nbgrader="{&quot;cell_type&quot;:&quot;markdown&quot;,&quot;checksum&quot;:&quot;48f97c6b49b742a0a7ebbd9fc0415266&quot;,&quot;grade&quot;:false,&quot;grade_id&quot;:&quot;cell-ad05bf85bb55dc8e&quot;,&quot;locked&quot;:true,&quot;schema_version&quot;:3,&quot;solution&quot;:false}">
<h2>Feedback</h2>
</section>
<div class="cell code" data-deletable="false" id="MBIVjKJeciFN"
data-nbgrader="{&quot;cell_type&quot;:&quot;code&quot;,&quot;checksum&quot;:&quot;ed936ab53a1391c5e6af8df699a1dbf5&quot;,&quot;grade&quot;:false,&quot;grade_id&quot;:&quot;feedback&quot;,&quot;locked&quot;:false,&quot;schema_version&quot;:3,&quot;solution&quot;:true}">
<div class="sourceCode" id="cb37"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> feedback():</span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">&quot;&quot;&quot;Provide feedback on the contents of this exercise</span></span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-4"><a href="#cb37-4" aria-hidden="true" tabindex="-1"></a><span class="co">    Returns:</span></span>
<span id="cb37-5"><a href="#cb37-5" aria-hidden="true" tabindex="-1"></a><span class="co">        string</span></span>
<span id="cb37-6"><a href="#cb37-6" aria-hidden="true" tabindex="-1"></a><span class="co">    &quot;&quot;&quot;</span></span>
<span id="cb37-7"><a href="#cb37-7" aria-hidden="true" tabindex="-1"></a>    <span class="co"># YOUR CODE HERE</span></span>
<span id="cb37-8"><a href="#cb37-8" aria-hidden="true" tabindex="-1"></a>    <span class="co"># N/A</span></span>
<span id="cb37-9"><a href="#cb37-9" aria-hidden="true" tabindex="-1"></a>    <span class="co"># raise NotImplementedError()</span></span></code></pre></div>
</div>
<div class="cell code" data-deletable="false" data-editable="false"
id="IHRYSQvUciFN"
data-nbgrader="{&quot;cell_type&quot;:&quot;code&quot;,&quot;checksum&quot;:&quot;f39f6185a54850c2f1f9b5b2a17b7543&quot;,&quot;grade&quot;:true,&quot;grade_id&quot;:&quot;feedback-tests&quot;,&quot;locked&quot;:true,&quot;points&quot;:0,&quot;schema_version&quot;:3,&quot;solution&quot;:false}">
<div class="sourceCode" id="cb38"><pre
class="sourceCode python"><code class="sourceCode python"></code></pre></div>
</div>
</body>
</html>
